/*
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the BSD-style license found in the
 * LICENSE file in the root directory of this source tree.
 */

#include <array>
#include <functional>
#include <stdexcept>

#include <gtest/gtest.h>
#include <chrono>

#include "flashlight/fl/autograd/autograd.h"
#include "flashlight/fl/autograd/backend/miopen/MiOpenUtils.h"
#include "flashlight/fl/common/DynamicBenchmark.h"
#include "flashlight/fl/common/Init.h"
#include "flashlight/fl/common/Logging.h"
#include "flashlight/fl/common/MiOpenUtils.h"
#include "flashlight/fl/common/common.h"

struct Timer {
  Timer(std::chrono::duration<double>& elapsed)
      : start_(std::chrono::high_resolution_clock::now()), elapsed_(elapsed) {}
  ~Timer() {
    elapsed_ += std::chrono::duration_cast<std::chrono::duration<double>>(
        std::chrono::high_resolution_clock::now() - start_);
  }
  std::chrono::high_resolution_clock::time_point start_;
  std::chrono::duration<double>& elapsed_;
};

// https: //
// github.com/tensorflow/tensorflow/blob/1d74f869fece4375c7fa3733ce28f2f082013b22/tensorflow/stream_executor/rocm/rocm_dnn.cc#L341
// https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/miopen/Conv_miopen.cpp
// https://rocmsoftwareplatform.github.io/MIOpen/doc/html/find_and_immediate.html
// https://github.com/ROCmSoftwarePlatform/MIOpen/blob/1673b9f0ff6148f1972080240a70c73b5915ff0b/include/miopen/miopen.h#L988

using namespace fl;
using namespace fl::miopen;

namespace fl {
namespace find {

enum class KernelMode { F32 = 0, F32_ALLOW_CONVERSION = 1, F16 = 2 };

std::shared_ptr<fl::DynamicBenchmark> createBenchmarkOptions() {
  return std::make_shared<fl::DynamicBenchmark>(
      std::make_shared<fl::DynamicBenchmarkOptions<KernelMode>>(
          std::vector<KernelMode>({KernelMode::F32,
                                   KernelMode::F32_ALLOW_CONVERSION,
                                   KernelMode::F16}),
          fl::kDynamicBenchmarkDefaultCount));
}

// Get the algorithm which gives best performance.
template <typename T>
T getBestAlgorithm(const std::vector<T>& algoPerfs) {
  if (algoPerfs.empty()) {
    throw std::invalid_argument("Error while finding MiOpen Conv Algorithm.");
  }

  float fastestTime = std::numeric_limits<float>::max();
  int fastestIdx = -1;
  for (int i = 0; i < algoPerfs.size(); ++i) {
    if (algoPerfs[i].workspace_size < kWorkspaceSizeLimitBytes &&
        algoPerfs[i].time < fastestTime) {
      fastestTime = algoPerfs[i].time;
      fastestIdx = i;
    }
  }
  if (fastestIdx > 0) {
    return algoPerfs[fastestIdx];
  } else {
    throw std::runtime_error("Error while finding MiOpen Conv Algorithm.");
  }
}

miopenConvSolution_t getFwdAlgo(
    miopenHandle_t handle,
    const miopenTensorDescriptor_t& xDesc,
    const void* x,
    const miopenTensorDescriptor_t& wDesc,
    const void* w,
    const miopenConvolutionDescriptor_t& convDesc,
    const miopenTensorDescriptor_t& yDesc,
    void* y) {
  size_t maxSolutionCount = 0;
  MIOPEN_CHECK_ERR(miopenConvolutionForwardGetSolutionCount(
      handle, wDesc, xDesc, convDesc, yDesc, &maxSolutionCount));

  size_t solutionCount = 0;
  std::vector<miopenConvSolution_t> solutions(maxSolutionCount);

  MIOPEN_CHECK_ERR(miopenConvolutionForwardGetSolution(
      handle,
      wDesc,
      xDesc,
      convDesc,
      yDesc,
      maxSolutionCount,
      &solutionCount,
      solutions.data()));

  FL_LOG(fl::INFO) << "Number of conv solutions actual: " << solutionCount;
  for (size_t i = 0; i < solutionCount; i++) {
    miopenConvSolution_t solution = solutions[i];
    FL_LOG(fl::INFO) << "solution " << i
                     << " (time, mem, id, algo) =  " << solution.time << ", "
                     << solution.workspace_size << ", " << solution.solution_id
                     << ", " << PrettyString(solution.algorithm);
    MIOPEN_CHECK_ERR(miopenConvolutionForwardCompileSolution(
        handle, wDesc, xDesc, convDesc, yDesc, solution.solution_id));
  }

  return getBestAlgorithm(solutions);
}

miopenConvSolution_t getBwdDataAlgo(
    const miopenTensorDescriptor_t& xDesc,
    const miopenTensorDescriptor_t& wDesc,
    const miopenConvolutionDescriptor_t& convDesc,
    const miopenTensorDescriptor_t& yDesc,
    bool isStrided,
    const af::dtype arithmeticPrecision) {
  size_t numBwdDataAlgoRequested = 0;
  size_t numBwdDataAlgoReturned = 0;

  MIOPEN_CHECK_ERR(miopenConvolutionBackwardDataGetSolutionCount(
      fl::getMiOpenHandle(),
      yDesc,
      wDesc,
      convDesc,
      xDesc,
      &numBwdDataAlgoRequested));

  std::vector<miopenConvSolution_t> bwdDataAlgoPerfs(numBwdDataAlgoRequested);

  // https://github.com/ROCmSoftwarePlatform/MIOpen/blob/1673b9f0ff6148f1972080240a70c73b5915ff0b/include/miopen/miopen.h#L1199
  MIOPEN_CHECK_ERR(miopenConvolutionBackwardDataGetSolution(
      fl::getMiOpenHandle(),
      yDesc,
      wDesc,
      convDesc,
      xDesc,
      numBwdDataAlgoRequested,
      &numBwdDataAlgoReturned,
      bwdDataAlgoPerfs.data()));

  FL_LOG(fl::INFO) << "Number of backward data bwdDataAlgoPerfs actual: "
                   << numBwdDataAlgoReturned;
  for (size_t i = 0; i < numBwdDataAlgoReturned; i++) {
    miopenConvSolution_t solution = bwdDataAlgoPerfs[i];
    FL_LOG(fl::INFO) << "solution " << i
                     << " (time, mem, id, algo) =  " << solution.time << ", "
                     << solution.workspace_size << ", " << solution.solution_id
                     << ", " << PrettyString(solution.algorithm);

    MIOPEN_CHECK_ERR(miopenConvolutionBackwardDataCompileSolution(
        fl::getMiOpenHandle(),
        yDesc,
        wDesc,
        convDesc,
        xDesc,
        solution.solution_id));
  }

  return getBestAlgorithm(bwdDataAlgoPerfs);
}

// Variable __conv2d(
//     const Variable& input,
//     const Variable& weights,
//     const Variable& bias,
//     int sx,
//     int sy,
//     int px,
//     int py,
//     int dx,
//     int dy,
//     int groups,
//     std::shared_ptr<fl::detail::ConvBenchmarks> benchmarks) {
//   FL_VARIABLE_DTYPES_MATCH_CHECK(input, weights, bias);

//   auto hasBias = bias.elements() > 0;

//   auto inDesc = TensorDescriptor(input);
//   auto wtDesc = TensorDescriptor(weights);
//   auto convDesc = ConvDescriptor(input.type(), px, py, sx, sy, dx, dy,
//   groups);

//   int dn = input.dims(3) + 2;
//   std::vector<int> odims(dn); // in BDYX
//   MIOPEN_CHECK_ERR(miopenGetConvolutionNdForwardOutputDim(
//       convDesc.descriptor,
//       inDesc.descriptor,
//       wtDesc.descriptor,
//       &dn,
//       odims.data()));
//   FL_LOG(fl::INFO) << "dn=" << dn;
//   auto output = af::array(odims[3], odims[2], odims[1], odims[0],
//   input.type()); auto outDesc = TensorDescriptor(output); af::print("output
//   after", output);

//   miopenHandle_t handle = getMiOpenHandle();
//   {
//     DevicePtr inPtr(input.array());
//     DevicePtr wtPtr(weights.array());
//     DevicePtr outPtr(output);

//     miopenConvSolution_t fwdAlgo = getFwdAlgo(
//         handle,
//         inDesc.descriptor,
//         inPtr.get(),
//         wtDesc.descriptor,
//         wtPtr.get(),
//         convDesc.descriptor,
//         outDesc.descriptor,
//         outPtr.get());

//     size_t workSpaceSize = 0;
//     MIOPEN_CHECK_ERR(miopenConvolutionForwardGetSolutionWorkspaceSize(
//         handle,
//         wtDesc.descriptor,
//         inDesc.descriptor,
//         convDesc.descriptor,
//         outDesc.descriptor,
//         fwdAlgo.solution_id,
//         &workSpaceSize));

//     // try {
//     //   wspace = af::array(solutions[0].workspace_size, af::dtype::b8);
//     // } catch (const std::exception& e) {
//     //   if (solutions.size() > 1) {
//     //     wspace = af::array(solutions[1].workspace_size, af::dtype::b8);
//     //   } else {
//     //     throw;
//     //   }
//     // }

//     FL_LOG(fl::INFO) << "workSpaceSize=" << workSpaceSize;

//     auto wspace = af::array(workSpaceSize, af::dtype::b8);
//     DevicePtr wspacePtr(wspace);

//     MIOPEN_CHECK_ERR(miopenConvolutionForwardImmediate(
//         handle,
//         wtDesc.descriptor,
//         wtPtr.get(),
//         inDesc.descriptor,
//         inPtr.get(),
//         convDesc.descriptor,
//         outDesc.descriptor,
//         outPtr.get(),
//         wspacePtr.get(),
//         workSpaceSize,
//         fwdAlgo.solution_id));

//     if (hasBias) {
//       af::print("bias", bias.array());
//       output = output + bias.array();
//     }

//     af::print("output after", output);
//   }

//   auto gradFunc = [sx, sy, px, py, dx, dy, hasBias, groups, benchmarks](
//                       std::vector<Variable>& inputs,
//                       const Variable& gradOutput) {
//     // Create benchmarks if needed
//     if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//       if (!benchmarks->bwdFilterBenchmark) {
//         benchmarks->bwdFilterBenchmark = createBenchmarkOptions();
//       }
//       if (!benchmarks->bwdDataBenchmark) {
//         benchmarks->bwdDataBenchmark = createBenchmarkOptions();
//       }
//       if (!benchmarks->bwdBiasBenchmark) {
//         benchmarks->bwdBiasBenchmark = createBenchmarkOptions();
//       }
//     }

//     auto& in = inputs[0];
//     auto& wt = inputs[1];

//     // Create default descriptors assuming no casts. If dynamic
//     // benchmarking suggests input or weight casting should occur, these
//     // descriptors may not be used/new ones with the correct types will be
//     used
//     // instead.
//     auto iDesc = TensorDescriptor(in);
//     auto wDesc = FilterDescriptor(wt.array());
//     auto cDesc = ConvDescriptor(in.type(), px, py, sx, sy, dx, dy, groups);
//     auto oDesc = TensorDescriptor(gradOutput.array());

//     auto hndl = getMiOpenHandle();

//     auto scalarsType = in.type() == f16 ? f32 : in.type();
//     const void* oneg = kOne(scalarsType);
//     const void* zerog = kZero(scalarsType);

//     // Bias gradients
//     if (hasBias && inputs.size() > 2 && inputs[2].isCalcGrad()) {
//       auto& bias = inputs[2];
//       auto convolutionBackwardBias = [&bias, &hndl, oneg, zerog](
//                                          const af::array& bsArray,
//                                          const af::array& gradOutput,
//                                          const TensorDescriptor& oDesc) {
//         DevicePtr gradResultPtr(gradOutput);

//         auto gradBias =
//             Variable(af::array(bsArray.dims(), bsArray.type()), false);
//         {
//           DevicePtr gradBiasPtr(gradBias.array());
//           auto bDesc = TensorDescriptor(bsArray);
//           MIOPEN_CHECK_ERR(miopenConvolutionBackwardBias(
//               hndl,
//               oneg,
//               oDesc.descriptor,
//               gradResultPtr.get(),
//               zerog,
//               bDesc.descriptor,
//               gradBiasPtr.get()));
//         }
//         bias.addGrad(gradBias);
//       };

//       if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//         KernelMode biasBwdOption =
//             benchmarks->bwdBiasBenchmark
//                 ->getOptions<DynamicBenchmarkOptions<KernelMode>>()
//                 ->currentOption();

//         if (in.type() == af::dtype::f16 && biasBwdOption == KernelMode::F32
//         &&
//             biasBwdOption == KernelMode::F32_ALLOW_CONVERSION) {
//           // The input type of fp16, but the result of the dynamic benchmark
//           is
//           // that using fp32 kernels is faster for computing bwd with fp16
//           // kernels, including the cast
//           af::array biasF32;
//           af::array gradOutputF32;
//           // Time cast bias and grad output if benchmarking
//           benchmarks->bwdBiasBenchmark->audit(
//               [&bias, &gradOutput, &biasF32, &gradOutputF32]() {
//                 biasF32 = bias.array().as(af::dtype::f32);
//                 gradOutputF32 = gradOutput.array().as(af::dtype::f32);
//               },
//               /* incrementCount = */ false);
//           auto oDescF32 = TensorDescriptor(gradOutputF32);
//           // Perform bias gradient computation
//           benchmarks->bwdBiasBenchmark->audit([&convolutionBackwardBias,
//                                                &biasF32,
//                                                &gradOutputF32,
//                                                &oDescF32]() {
//             convolutionBackwardBias(biasF32, gradOutputF32, oDescF32);
//           });
//         } else {
//           // Grad output and bias types are already the same, so perform the
//           // computation using whatever input type is given
//           benchmarks->bwdBiasBenchmark->audit(
//               [&convolutionBackwardBias, &bias, &gradOutput, &oDesc]() {
//                 convolutionBackwardBias(
//                     bias.array(), gradOutput.array(), oDesc);
//               });
//         }
//       } else {
//         // No benchmark; proceed normally
//         convolutionBackwardBias(bias.array(), gradOutput.array(), oDesc);
//       }
//     }

//     // Gradients with respect to the input
//     auto convolutionBackwardData =
//         [&hndl, &in, &benchmarks, oneg, zerog, dx, dy](
//             const af::array& inArray,
//             const af::array& wtArray,
//             const af::array& gradOutputArray,
//             TensorDescriptor& iDesc,
//             FilterDescriptor& wDesc,
//             ConvDescriptor& cDesc,
//             TensorDescriptor& oDesc) {
//           if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//             // setMiOpenMathType(
//             //     cDesc,
//             //     benchmarks->bwdDataBenchmark
//             //         ->getOptions<DynamicBenchmarkOptions<KernelMode>>());

//             // Set the type of the tensors
//           }

//           DevicePtr wPtr(wtArray);
//           if (in.isCalcGrad()) {
//             bool isStrided = (dx * dy) > 1;
//             auto bwdDataAlgoBestPerf = getBwdDataAlgo(
//                 iDesc.descriptor,
//                 wDesc.descriptor,
//                 cDesc.descriptor,
//                 oDesc.descriptor,
//                 isStrided,
//                 inArray.type());

//             size_t workSpaceSize = 0;
//             MIOPEN_CHECK_ERR(miopenConvolutionBackwardDataGetWorkSpaceSize(
//                 hndl,
//                 oDesc.descriptor,
//                 wDesc.descriptor,
//                 cDesc.descriptor,
//                 iDesc.descriptor,
//                 &workSpaceSize));

//             auto ws = af::array(workSpaceSize, af::dtype::b8);

//             auto gradInput =
//                 Variable(af::array(inArray.dims(), inArray.type()), false);
//             {
//               DevicePtr gradInputPtr(gradInput.array());
//               DevicePtr gradResultPtr(gradOutputArray);
//               DevicePtr wsPtr(ws);
//               MIOPEN_CHECK_ERR(miopenConvolutionBackwardData(
//                   hndl,
//                   oneg,
//                   wDesc.descriptor,
//                   wPtr.get(),
//                   oDesc.descriptor,
//                   gradResultPtr.get(),
//                   cDesc.descriptor,
//                   bwdDataAlgoBestPerf.algorithm,
//                   wsPtr.get(),
//                   workSpaceSize,
//                   zerog,
//                   iDesc.descriptor,
//                   gradInputPtr.get()));
//             }
//             in.addGrad(gradInput);
//           }
//         };

//     if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//       KernelMode dataBwdOption =
//           benchmarks->bwdDataBenchmark
//               ->getOptions<DynamicBenchmarkOptions<KernelMode>>()
//               ->currentOption();

//       if (in.type() == af::dtype::f16 && dataBwdOption == KernelMode::F32 &&
//           dataBwdOption == KernelMode::F32_ALLOW_CONVERSION) {
//         // The input type of fp16, but the result of the dynamic benchmark is
//         // that using fp32 kernels is faster for computing bwd with fp16
//         // kernels, including the cast
//         af::array inArrayF32;
//         af::array wtArrayF32;
//         af::array gradOutputArrayF32;
//         benchmarks->bwdDataBenchmark->audit(
//             [&in,
//              &inArrayF32,
//              &wt,
//              &wtArrayF32,
//              &gradOutput,
//              &gradOutputArrayF32]() {
//               inArrayF32 = in.array().as(af::dtype::f32);
//               wtArrayF32 = wt.array().as(af::dtype::f32);
//               gradOutputArrayF32 = gradOutput.array().as(af::dtype::f32);
//             },
//             /* incrementCount = */ false);

//         auto iDescF32 = TensorDescriptor(inArrayF32);
//         auto wDescF32 = FilterDescriptor(wtArrayF32);
//         auto cDescF32 =
//             ConvDescriptor(af::dtype::f32, px, py, sx, sy, dx, dy, groups);
//         auto oDescF32 = TensorDescriptor(gradOutputArrayF32);
//         // core bwd data computation
//         benchmarks->bwdDataBenchmark->audit([&convolutionBackwardData,
//                                              &inArrayF32,
//                                              &wtArrayF32,
//                                              &gradOutputArrayF32,
//                                              &iDescF32,
//                                              &wDescF32,
//                                              &cDescF32,
//                                              &oDescF32]() {
//           convolutionBackwardData(
//               inArrayF32,
//               wtArrayF32,
//               gradOutputArrayF32,
//               iDescF32,
//               wDescF32,
//               cDescF32,
//               oDescF32);
//         });
//       } else {
//         benchmarks->bwdDataBenchmark->audit([&convolutionBackwardData,
//                                              &in,
//                                              &wt,
//                                              &gradOutput,
//                                              &iDesc,
//                                              &wDesc,
//                                              &cDesc,
//                                              &oDesc]() {
//           convolutionBackwardData(
//               in.array(),
//               wt.array(),
//               gradOutput.array(),
//               iDesc,
//               wDesc,
//               cDesc,
//               oDesc);
//         });
//       }
//     } else {
//       // No benchmarking - proceed normally
//       convolutionBackwardData(
//           in.array(),
//           wt.array(),
//           gradOutput.array(),
//           iDesc,
//           wDesc,
//           cDesc,
//           oDesc);
//     }

//     // Gradients with respect to the filter
//     auto convolutionBackwardFilter = [&hndl, &wt, &benchmarks, oneg, zerog](
//                                          const af::array& inArray,
//                                          const af::array& wtArray,
//                                          const af::array& gradOutputArray,
//                                          TensorDescriptor& iDesc,
//                                          FilterDescriptor& wDesc,
//                                          ConvDescriptor& cDesc,
//                                          TensorDescriptor& oDesc) {
//       if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//         // setMiOpenMathType(
//         //     cDesc,
//         //     benchmarks->bwdFilterBenchmark
//         //         ->getOptions<DynamicBenchmarkOptions<KernelMode>>());

//         // Set the type of the tensors
//       }

//       DevicePtr iPtr(inArray);
//       if (wt.isCalcGrad()) {
//         auto bwdFilterAlgoBestPerf = getBwdFilterAlgo(
//             iDesc.descriptor,
//             wDesc.descriptor,
//             cDesc.descriptor,
//             oDesc.descriptor,
//             inArray.type());

//         af::array ws;
//         try {
//           ws = af::array(bwdFilterAlgoBestPerf.memory, af::dtype::b8);
//         } catch (const std::exception& e) {
//           bwdFilterAlgoBestPerf.algo = kBwdFilterDefaultAlgo;
//           MIOPEN_CHECK_ERR(miopenConvolutionBackwardWeightsGetWorkSpaceSize(
//               hndl,
//               iDesc.descriptor,
//               oDesc.descriptor,
//               cDesc.descriptor,
//               wDesc.descriptor,
//               bwdFilterAlgoBestPerf.algo,
//               &bwdFilterAlgoBestPerf.memory));
//           ws = af::array(bwdFilterAlgoBestPerf.memory, af::dtype::b8);
//         }
//         auto gradWeight =
//             Variable(af::array(wtArray.dims(), wtArray.type()), false);
//         {
//           DevicePtr gradWeightPtr(gradWeight.array());
//           DevicePtr gradResultPtr(gradOutputArray);
//           DevicePtr wsPtr(ws);
//           MIOPEN_CHECK_ERR(miopenConvolutionBackwardWeights(
//               hndl,
//               oneg,
//               iDesc.descriptor,
//               iPtr.get(),
//               oDesc.descriptor,
//               gradResultPtr.get(),
//               cDesc.descriptor,
//               bwdFilterAlgoBestPerf.algo,
//               wsPtr.get(),
//               bwdFilterAlgoBestPerf.memory,
//               zerog,
//               wDesc.descriptor,
//               gradWeightPtr.get()));
//         }
//         wt.addGrad(gradWeight);
//       }
//     };

//     if (benchmarks && DynamicBenchmark::getBenchmarkMode()) {
//       KernelMode dataBwdOption =
//           benchmarks->bwdFilterBenchmark
//               ->getOptions<DynamicBenchmarkOptions<KernelMode>>()
//               ->currentOption();

//       if (in.type() == af::dtype::f16 && dataBwdOption == KernelMode::F32 &&
//           dataBwdOption == KernelMode::F32_ALLOW_CONVERSION) {
//         // The input type of fp16, but the result of the dynamic benchmark is
//         // that using fp32 kernels is faster for computing bwd with fp16
//         // kernels, including the cast
//         af::array inArrayF32;
//         af::array wtArrayF32;
//         af::array gradOutputArrayF32;
//         benchmarks->bwdFilterBenchmark->audit(
//             [&in,
//              &inArrayF32,
//              &wt,
//              &wtArrayF32,
//              &gradOutput,
//              &gradOutputArrayF32]() {
//               inArrayF32 = in.array().as(af::dtype::f32);
//               wtArrayF32 = wt.array().as(af::dtype::f32);
//               gradOutputArrayF32 = gradOutput.array().as(af::dtype::f32);
//             },
//             /* incrementCount = */ false);

//         auto iDescF32 = TensorDescriptor(inArrayF32);
//         auto wDescF32 = FilterDescriptor(wtArrayF32);
//         auto cDescF32 =
//             ConvDescriptor(af::dtype::f32, px, py, sx, sy, dx, dy, groups);
//         auto oDescF32 = TensorDescriptor(gradOutputArrayF32);
//         // core bwd data computation
//         benchmarks->bwdFilterBenchmark->audit([&convolutionBackwardFilter,
//                                                &inArrayF32,
//                                                &wtArrayF32,
//                                                &gradOutputArrayF32,
//                                                &iDescF32,
//                                                &wDescF32,
//                                                &cDescF32,
//                                                &oDescF32]() {
//           convolutionBackwardFilter(
//               inArrayF32,
//               wtArrayF32,
//               gradOutputArrayF32,
//               iDescF32,
//               wDescF32,
//               cDescF32,
//               oDescF32);
//         });
//       } else {
//         benchmarks->bwdFilterBenchmark->audit([&convolutionBackwardFilter,
//                                                &in,
//                                                &wt,
//                                                &gradOutput,
//                                                &iDesc,
//                                                &wDesc,
//                                                &cDesc,
//                                                &oDesc]() {
//           convolutionBackwardFilter(
//               in.array(),
//               wt.array(),
//               gradOutput.array(),
//               iDesc,
//               wDesc,
//               cDesc,
//               oDesc);
//         });
//       }
//     } else {
//       convolutionBackwardFilter(
//           in.array(),
//           wt.array(),
//           gradOutput.array(),
//           iDesc,
//           wDesc,
//           cDesc,
//           oDesc);
//     }
//   };

//   if (hasBias) {
//     return Variable(output, {input, weights, bias}, gradFunc);
//   }
//   return Variable(output, {input, weights}, gradFunc);
// }

} // namespace find

// Variable __pool2d(
//     const Variable& input,
//     int wx,
//     int wy,
//     int sx,
//     int sy,
//     int px,
//     int py,
//     PoolingMode mode /* = PoolingMode::MAX */) {
//   auto in_desc = TensorDescriptor(input);

//   // init pooling descriptor
//   auto pool_desc = PoolingDescriptor(wx, wy, sx, sy, px, py, mode);

//   // init output descriptor
//   auto ix = input.dims(0);
//   auto iy = input.dims(1);
//   auto ox = 1 + (ix + 2 * px - wx) / sx;
//   auto oy = 1 + (iy + 2 * py - wy) / sy;

//   auto output = af::randu(ox, oy, input.dims(2), input.dims(3), input.type());
//   auto out_desc = TensorDescriptor(output);
//   size_t workSpaceSize = 0;
//   {
//     DevicePtr inputraw(input.array());
//     DevicePtr resultraw(output);

//     auto handle = getMiOpenHandle();
//     const void* one = kOne(input.type());
//     const void* zero = kZero(input.type());

//     MIOPEN_CHECK_ERR(miopenPoolingGetWorkSpaceSizeV2(
//         pool_desc.descriptor, out_desc.descriptor, &workSpaceSize));
//     FL_LOG(fl::INFO) << "workSpaceSize=" << workSpaceSize;
//     auto wspace = af::array(workSpaceSize, af::dtype::b8);
//     DevicePtr wspacePtr(wspace);

//     MIOPEN_CHECK_ERR(miopenPoolingForward(
//         handle,
//         pool_desc.descriptor,
//         /* alpha= */ one,
//         in_desc.descriptor,
//         inputraw.get(),
//         /* beta = */ zero,
//         out_desc.descriptor,
//         resultraw.get(),
//         /* do_backward= */ true,
//         wspacePtr.get(),
//         workSpaceSize));
//   }
//   auto gradFunc = [wx, wy, sx, sy, px, py, mode, output, wspace, workSpaceSize](
//                       std::vector<Variable>& inputs,
//                       const Variable& grad_output) {
//     auto& in = inputs[0];
//     if (!in.isCalcGrad()) {
//       return;
//     }
//     auto i_desc = TensorDescriptor(in);
//     auto o_desc = TensorDescriptor(output);
//     auto p_desc = PoolingDescriptor(wx, wy, sx, sy, px, py, mode);

//     auto grad_input = Variable(af::array(in.dims(), in.type()), false);

//     auto hndl = getMiOpenHandle();
//     const void* oneg = kOne(in.type());
//     const void* zerog = kZero(in.type());

//     {
//       DevicePtr inraw(in.array());
//       DevicePtr outraw(output);
//       DevicePtr gradresultraw(grad_output.array());
//       DevicePtr gradinputraw(grad_input.array());
//       DevicePtr wspacePtr(wspace);

//       MIOPEN_CHECK_ERR(miopenPoolingBackward(
//           hndl,
//           p_desc.descriptor,
//           oneg,
//           o_desc.descriptor,
//           outraw.get(),
//           o_desc.descriptor,
//           gradresultraw.get(),
//           i_desc.descriptor,
//           inraw.get(),
//           &beta,
//           i_desc.descriptor,
//           gradinputraw.get(),
//           wspacePtr.get()));
//     }
//     in.addGrad(grad_input);
//   };
//   return Variable(output, {input}, gradFunc);
// }
} // namespace fl

TEST(MiOpenTest, Conv2D) {
  auto input = Variable(af::randu(10, 9, 8, 7, af::dtype::f32), true);
  auto weights = Variable(af::randu(4, 3, 8, 6, af::dtype::f32), true);
  auto bs = Variable(af::randu(1, 1, 6, 1, af::dtype::f32), true);
  int px = 2, py = 1;
  int sx = 1, sy = 1;
  int dx = 1, dy = 1;
  int groups = 1;

  auto output = fl::conv2d(input, weights, bs, sx, sy, px, py, dx, dy, groups);
}

TEST(MiOpenTest, Conv2DSmall) {
  auto input = Variable(af::randu(4, 4, 1, 1, af::dtype::f32), true);
  auto weights = Variable(af::randu(3, 3, 1, 1, af::dtype::f32), true);
  auto bs = Variable(af::randu(1, 1, 1, 1, af::dtype::f32), true);
  int px = 1, py = 1;
  int sx = 1, sy = 1;
  int dx = 1, dy = 1;
  int groups = 1;

  auto output = fl::conv2d(input, weights, bs, sx, sy, px, py, dx, dy, groups);
}

// class ReducetDescriptor {
//  public:
//   explicit ReducetDescriptor(miopenReduceTensorOp_t op);
//   ~ReducetDescriptor();

//   miopenReduceTensorDescriptor_t descriptor;
// };

// ReducetDescriptor::ReducetDescriptor(miopenReduceTensorOp_t op) {
//   MIOPEN_CHECK_ERR(miopenCreateReduceTensorDescriptor(&descriptor));

//   MIOPEN_CHECK_ERR(miopenSetReduceTensorDescriptor(
//       descriptor,
//       op,
//       miopenFloat,
//       MIOPEN_PROPAGATE_NAN,
//       MIOPEN_REDUCE_TENSOR_NO_INDICES,
//       MIOPEN_32BIT_INDICES));

//   if (groups > 1) {
//     MIOPEN_CHECK_ERR(miopenSetConvolutionGroupCount(descriptor, groups));
//   }
// }

// ReducetDescriptor::~ReducetDescriptor() {
//   MIOPEN_CHECK_ERR(miopenDestroyReduceTensorDescriptor(descriptor));
// }

// TEST(MiOpenTest, Addition) {
//   {
//     auto a = af::randu(10, 9, 8, 7, af::dtype::f32);
//     auto b = af::randu(4, 3, 8, 6, af::dtype::f32);

//     auto aDesc = TensorDescriptor(bias.array());
//     DevicePtr bsPtr(bias.array());
//     auyto reduceDesc ReducetDescriptor();
//     output = output + fl::tileAs(bias, output.dims()).array();

//     MIOPEN_CHECK_ERR(miopenGetReductionIndicesSize(
//         handle, reduceDesc, inDesc, outDesc, &szIndices));
//     MIOPEN_CHECK_ERR(miopenGetReductionWorkspaceSize(
//         handle, reduceDesc, inDesc, outDesc, &szWorkspace));

//     MIOPEN_CHECK_ERR(miopenReduceTensor(
//         handle,
//         reduceDesc,
//         szIndices ? indicesBuffer : nullptr,
//         szIndices,
//         szWorkspace ? workspaceBuffer : nullptr,
//         szWorkspace,
//         &alpha,
//         inDesc,
//         inDevData,
//         &beta,
//         outDesc,
//         outDevData));

//     // warmup
//     auto c = add(a, b);
//     duration<double> elapsedMiopen;
//     for (int i = 0; i < 100; ++i) {
//       Timer additionTime(elapsedMiopen);
//       c = add(a, b);
//     }

//     duration<double> elapsedArrayFire;
//     auto c = a + b;
//     for (int i = 0; i < 100; ++i) {
//       Timer additionTime(elapsedArrayFire);
//       c = a + b;
//       c.sync();
//     }
//   }

  int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    fl::init();
    return RUN_ALL_TESTS();
  }
