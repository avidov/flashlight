{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InferenceAndAlignCTC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vqepaR4bZzJ"
      },
      "source": [
        "# Tutorial on ASR inference and alignment with CTC model \n",
        "Let's play with the pre-trained speech recognition model!\n",
        "\n",
        "Here we provide pre-trained speech recognition model with CTC loss on several open-sourced datasets, details can be found in [Rethinking Evaluation in ASR: Are Our Models Robust Enough?](https://arxiv.org/abs/2010.11745)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbTYA-j_vk-7"
      },
      "source": [
        "## Install `Flashlight`\n",
        "First we need to install `Flashlight` and its dependencies. `Flashlight` is installed from source, it takes **~16 minutes**. \n",
        "\n",
        "For installation out of colab notebook please use [link](https://github.com/facebookresearch/flashlight#building)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNciLYP5zSKf"
      },
      "source": [
        "# First, choose backend to build with\n",
        "backend = 'CUDA' #@param [\"CPU\", \"CUDA\"]\n",
        "# Clone Flashlight\n",
        "!git clone https://github.com/facebookresearch/flashlight.git\n",
        "# install all dependencies for colab notebook\n",
        "!source flashlight/scripts/colab/colab_install_deps.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL7tr8B4z7Y5"
      },
      "source": [
        "Build from current master. Builds the ASR app. Resulting binaries in `/content/flashlight/build/bin/asr`.\n",
        "\n",
        "If using a GPU Colab runtime, build the CUDA backend; else build the CPU backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZs5ucthy38A"
      },
      "source": [
        "# export necessary env variables\n",
        "%env MKLROOT=/opt/intel/mkl\n",
        "%env ArrayFire_DIR=/opt/arrayfire/share/ArrayFire/cmake\n",
        "%env DNNL_DIR=/opt/dnnl/dnnl_lnx_2.0.0_cpu_iomp/lib/cmake/dnnl\n",
        "\n",
        "if backend == \"CUDA\":\n",
        "  # Total time: ~13 minutes\n",
        "  !cd flashlight && mkdir -p build && cd build && \\\n",
        "  cmake .. -DCMAKE_BUILD_TYPE=Release \\\n",
        "           -DFL_BUILD_TESTS=OFF \\\n",
        "           -DFL_BUILD_EXAMPLES=OFF \\\n",
        "           -DFL_BUILD_APP_IMGCLASS=OFF \\\n",
        "           -DFL_BUILD_APP_LM=OFF && \\\n",
        "  make -j$(nproc)\n",
        "elif backend == \"CPU\":\n",
        "  # Total time: ~14 minutes\n",
        "  !cd flashlight && mkdir -p build && cd build && \\\n",
        "  cmake .. -DFL_BACKEND=CPU \\\n",
        "           -DCMAKE_BUILD_TYPE=Release \\\n",
        "           -DFL_BUILD_TESTS=OFF \\\n",
        "           -DFL_BUILD_EXAMPLES=OFF \\\n",
        "           -DFL_BUILD_APP_IMGCLASS=OFF \\\n",
        "           -DFL_BUILD_APP_LM=OFF && \\\n",
        "  make -j$(nproc)\n",
        "else:\n",
        "  raise ValueError(f\"Unknown backend {backend}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-V0U-Dow-vs"
      },
      "source": [
        "Let's take a look around."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6tRnX1iHCoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7a1ee2-3610-4180-8d3a-59f448010eeb"
      },
      "source": [
        "# Binaries are located in\n",
        "!ls flashlight/build/bin/asr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fl_asr_decode  fl_asr_train\t\t     fl_asr_tutorial_inference_ctc\n",
            "fl_asr_test    fl_asr_tutorial_finetune_ctc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9078zTzcdS3"
      },
      "source": [
        "## Inference: preparation steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfTJdH646cHb"
      },
      "source": [
        "### Download Models\n",
        "Download acoustic model, language model, tokens (defines predicted tokens) and lexicon (defines mapping between words and tokens sequence and used to restrict the beam search only to infer words from the lexicon) files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPDEovLVc46Z",
        "outputId": "3fc975c0-0a17-4cc0-8cc8-b946bbbd0f8d"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/am_transformer_ctc_stride3_letters_300Mparams.bin\n",
        "!wget https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/am_conformer_ctc_stride3_letters_25Mparams.bin\n",
        "!wget https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/tokens.txt\n",
        "!wget https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/lexicon.txt\n",
        "!wget https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin\n",
        "!mkdir audio\n",
        "for i in range(5):\n",
        "  path = \"https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-000{}.flac\".format(i)\n",
        "  !cd audio && wget $path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-23 20:36:28--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/am_transformer_ctc_stride3_letters_300Mparams.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2147270937 (2.0G) [application/octet-stream]\n",
            "Saving to: ‘am_transformer_ctc_stride3_letters_300Mparams.bin’\n",
            "\n",
            "am_transformer_ctc_ 100%[===================>]   2.00G  27.7MB/s    in 76s     \n",
            "\n",
            "2020-12-23 20:37:45 (27.0 MB/s) - ‘am_transformer_ctc_stride3_letters_300Mparams.bin’ saved [2147270937/2147270937]\n",
            "\n",
            "--2020-12-23 20:37:45--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/am_conformer_ctc_stride3_letters_25Mparams.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 221972787 (212M) [application/octet-stream]\n",
            "Saving to: ‘am_conformer_ctc_stride3_letters_25Mparams.bin’\n",
            "\n",
            "am_conformer_ctc_st 100%[===================>] 211.69M  27.3MB/s    in 8.4s    \n",
            "\n",
            "2020-12-23 20:37:54 (25.1 MB/s) - ‘am_conformer_ctc_stride3_letters_25Mparams.bin’ saved [221972787/221972787]\n",
            "\n",
            "--2020-12-23 20:37:54--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/tokens.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56 [binary/octet-stream]\n",
            "Saving to: ‘tokens.txt’\n",
            "\n",
            "tokens.txt          100%[===================>]      56  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-23 20:37:54 (11.8 MB/s) - ‘tokens.txt’ saved [56/56]\n",
            "\n",
            "--2020-12-23 20:37:54--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/lexicon.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4965720 (4.7M) [text/plain]\n",
            "Saving to: ‘lexicon.txt’\n",
            "\n",
            "lexicon.txt         100%[===================>]   4.74M  8.20MB/s    in 0.6s    \n",
            "\n",
            "2020-12-23 20:37:55 (8.20 MB/s) - ‘lexicon.txt’ saved [4965720/4965720]\n",
            "\n",
            "--2020-12-23 20:37:55--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2627163608 (2.4G) [application/octet-stream]\n",
            "Saving to: ‘lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin’\n",
            "\n",
            "lm_common_crawl_sma 100%[===================>]   2.45G  27.0MB/s    in 94s     \n",
            "\n",
            "2020-12-23 20:39:30 (26.6 MB/s) - ‘lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin’ saved [2627163608/2627163608]\n",
            "\n",
            "--2020-12-23 20:39:30--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-0000.flac\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200761 (196K) [audio/flac]\n",
            "Saving to: ‘116-288045-0000.flac’\n",
            "\n",
            "116-288045-0000.fla 100%[===================>] 196.06K   896KB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 20:39:31 (896 KB/s) - ‘116-288045-0000.flac’ saved [200761/200761]\n",
            "\n",
            "--2020-12-23 20:39:31--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-0001.flac\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149910 (146K) [audio/flac]\n",
            "Saving to: ‘116-288045-0001.flac’\n",
            "\n",
            "116-288045-0001.fla 100%[===================>] 146.40K   683KB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 20:39:31 (683 KB/s) - ‘116-288045-0001.flac’ saved [149910/149910]\n",
            "\n",
            "--2020-12-23 20:39:31--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-0002.flac\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173844 (170K) [audio/flac]\n",
            "Saving to: ‘116-288045-0002.flac’\n",
            "\n",
            "116-288045-0002.fla 100%[===================>] 169.77K   769KB/s    in 0.2s    \n",
            "\n",
            "2020-12-23 20:39:32 (769 KB/s) - ‘116-288045-0002.flac’ saved [173844/173844]\n",
            "\n",
            "--2020-12-23 20:39:32--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-0003.flac\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70783 (69K) [audio/flac]\n",
            "Saving to: ‘116-288045-0003.flac’\n",
            "\n",
            "116-288045-0003.fla 100%[===================>]  69.12K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-23 20:39:33 (498 KB/s) - ‘116-288045-0003.flac’ saved [70783/70783]\n",
            "\n",
            "--2020-12-23 20:39:33--  https://dl.fbaipublicfiles.com/wav2letter/rasr/tutorial/audio/116-288045-0004.flac\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72270 (71K) [audio/flac]\n",
            "Saving to: ‘116-288045-0004.flac’\n",
            "\n",
            "116-288045-0004.fla 100%[===================>]  70.58K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-23 20:39:33 (495 KB/s) - ‘116-288045-0004.flac’ saved [72270/72270]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuqJOR8_-nKJ"
      },
      "source": [
        "### Install dependencies to record/process audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmO_t36eTU-"
      },
      "source": [
        "!apt-get install sox\n",
        "!pip install ffmpeg-python sox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYcbvz531NzS"
      },
      "source": [
        "### Helper functions for inference\n",
        "\n",
        "Define helper functions to run inference binary as subprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4vfsNTayk1B"
      },
      "source": [
        "import os\n",
        "import signal\n",
        "from subprocess import Popen, PIPE  \n",
        "\n",
        "\n",
        "def read_current_output(process):\n",
        "    while True:\n",
        "        output = process.stderr.readline()\n",
        "        print(output.decode().strip())\n",
        "        if \"Waiting the input in the format\" in output.decode():\n",
        "          break;\n",
        "\n",
        "\n",
        "def create_process(cmd):\n",
        "    process = Popen([cmd],\n",
        "                    stdin=PIPE, stdout=PIPE, stderr=PIPE,\n",
        "                    shell=True, preexec_fn=os.setsid) \n",
        "    read_current_output(process)\n",
        "    return process\n",
        "\n",
        "\n",
        "def run_inference(audio_path, process):\n",
        "    process.stdin.write(\"{}\\n\".format(audio_path).encode())\n",
        "    process.stdin.flush()\n",
        "    read_current_output(process)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj32IH3HvjZo"
      },
      "source": [
        "### Run the inference process with a model\n",
        "\n",
        "We are using best parameters we found on validation sets of training data with a language model we provide in this tutorial. You can play with `beam_size` (increasing it, but inference time will increse too), `lm_weight` and `word_score`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppGOZZWR4t_y",
        "outputId": "cb411386-e5c3-4c91-bb92-0abed75fcb60"
      },
      "source": [
        "# you can switch here to small model am_conformer_ctc_stride3_letters_25Mparams.bin\n",
        "# set for it also lm_weight=2 and word_score=0\n",
        "inference_cmd = \"\"\"./flashlight/build/bin/asr/fl_asr_tutorial_inference_ctc \\\n",
        "  --am_path=am_transformer_ctc_stride3_letters_300Mparams.bin \\\n",
        "  --tokens_path=tokens.txt \\\n",
        "  --lexicon_path=lexicon.txt \\\n",
        "  --lm_path=lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin \\\n",
        "  --logtostderr=true \\\n",
        "  --sample_rate=16000 \\\n",
        "  --beam_size=50 \\\n",
        "  --beam_size_token=30 \\\n",
        "  --beam_threshold=100 \\\n",
        "  --lm_weight=1.5 \\\n",
        "  --word_score=0\"\"\"\n",
        "inference_process = create_process(inference_cmd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1223 21:06:02.916659  9835 InferenceCTC.cpp:65] Gflags after parsing\n",
            "--flagfile=;--fromenv=;--tryfromenv=;--undefok=;--tab_completion_columns=80;--tab_completion_word=;--help=false;--helpfull=false;--helpmatch=;--helpon=;--helppackage=false;--helpshort=false;--helpxml=false;--version=false;--am_path=am_transformer_ctc_stride3_letters_300Mparams.bin;--audio_list=;--beam_size=50;--beam_size_token=30;--beam_threshold=100;--lexicon_path=lexicon.txt;--lm_path=lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin;--lm_weight=1.5;--sample_rate=16000;--tokens_path=tokens.txt;--word_score=0;--alsologtoemail=;--alsologtostderr=false;--colorlogtostderr=false;--drop_log_memory=true;--log_backtrace_at=;--log_dir=;--log_link=;--log_prefix=true;--logbuflevel=0;--logbufsecs=30;--logemaillevel=999;--logfile_mode=436;--logmailer=/bin/mail;--logtostderr=true;--max_log_size=1800;--minloglevel=0;--stderrthreshold=2;--stop_logging_if_full_disk=false;--symbolize_stacktrace=true;--v=0;--vmodule=;\n",
            "I1223 21:06:02.916770  9835 InferenceCTC.cpp:88] [Inference tutorial for CTC] Reading acoustic model from am_transformer_ctc_stride3_letters_300Mparams.bin\n",
            "I1223 21:06:03.985780  9835 InferenceCTC.cpp:137] [Inference tutorial for CTC] Network is loaded.\n",
            "I1223 21:06:04.251106  9835 InferenceCTC.cpp:149] [Inference tutorial for CTC] Number of classes/tokens in the network: 29\n",
            "I1223 21:06:04.251235  9835 InferenceCTC.cpp:152] [Inference tutorial for CTC] Number of words in the lexicon: 200001\n",
            "I1223 21:06:04.435906  9835 InferenceCTC.cpp:163] [Inference tutorial for CTC] Language model is constructed.\n",
            "I1223 21:06:05.346547  9835 InferenceCTC.cpp:174] [Inference tutorial for CTC] Trie is planted.\n",
            "I1223 21:06:05.346582  9835 InferenceCTC.cpp:193] [Inference tutorial for CTC] Beam search decoder is created\n",
            "I1223 21:06:05.346601  9835 InferenceCTC.cpp:233] [Inference tutorial for CTC]: Waiting the input in the format [audio_path].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryc17nPTds7Q"
      },
      "source": [
        "## Inference: record audio from your microphone and run inference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5goRjHy1vRUj"
      },
      "source": [
        "### Let's record!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "1RscueA4dlz0",
        "outputId": "2ab6319e-cdf0-4afa-ee45-2af444cd6102"
      },
      "source": [
        "from flashlight.scripts.colab.record import record_audio\n",
        "record_audio(\"recorded_audio\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var recordButton = document.createElement(\"BUTTON\");\n",
              "recordButton.appendChild(\n",
              "  document.createTextNode(\"Press to start recording\")\n",
              ");\n",
              "restyleButtonBeforeRecording();\n",
              "\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "my_div.appendChild(recordButton);\n",
              "\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "\n",
              "function restyleButtonBeforeRecording() {\n",
              "  recordButton.style.width = '270px';\n",
              "  recordButton.style.height = '90';\n",
              "  recordButton.style.padding = '25px';\n",
              "  recordButton.style.backgroundColor = '#4CAF50';\n",
              "  recordButton.style.fontSize = '18px';\n",
              "}\n",
              "\n",
              "function restyleButtonForRecording() {\n",
              "  recordButton.style.backgroundColor = '#008CBA';\n",
              "  recordButton.innerText = \"Recording... press to stop\";\n",
              "}\n",
              "\n",
              "function restyleButtonForSaving() {\n",
              "  recordButton.style.backgroundColor = '#b34d4d';\n",
              "  recordButton.innerText = \"Saving... please wait!\"\n",
              "}\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      restyleButtonForSaving();\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "  recordButton.onclick = () => {\n",
              "    restyleButtonForRecording();\n",
              "    recordButton.onclick = () => {\n",
              "      toggleRecording();\n",
              "      sleep(2000).then(() => {\n",
              "        // wait 2000ms for the data to be available...\n",
              "        // ideally this should use something like await...\n",
              "        // console.log(\"Inside data:\" + base64data)\n",
              "        resolve(base64data.toString());\n",
              "      });\n",
              "    };\n",
              "    navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "  };\n",
              "});\n",
              "\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "output_file: recorded_audio.wav already exists and will be overwritten on build\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-LBEbd_zbg7"
      },
      "source": [
        "### Let's run inference on the audio file you have just recorded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pepX5Iens5cf",
        "outputId": "46155903-3608-4b9f-87fa-2fee0515654a"
      },
      "source": [
        "run_inference(\"recorded_audio.wav\", inference_process)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1223 21:06:12.590214  9835 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for recorded_audio.wav\n",
            "my my\n",
            "I1223 21:06:12.590270  9835 InferenceCTC.cpp:233] [Inference tutorial for CTC]: Waiting the input in the format [audio_path].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA57XYLuJWY1"
      },
      "source": [
        "### Finish the process to release memory\n",
        "\n",
        "You can skip if you still want to use this process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg1GgxrjJZrO"
      },
      "source": [
        "os.killpg(os.getpgid(inference_process.pid), signal.SIGTERM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utVPSMto1Yqh"
      },
      "source": [
        "## Inference: run inference on a set of audio files provided in the txt file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxKGQ0VHv8A4"
      },
      "source": [
        "### Prepare the file with all audio paths at first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI5oBu88zpM2"
      },
      "source": [
        "!ls audio/*.flac > audio.lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qyrGTYmKRaB",
        "outputId": "dab884c4-62d2-42b5-e016-1bb9a5712b62"
      },
      "source": [
        "!cat audio.lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audio/116-288045-0000.flac\n",
            "audio/116-288045-0001.flac\n",
            "audio/116-288045-0002.flac\n",
            "audio/116-288045-0003.flac\n",
            "audio/116-288045-0004.flac\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBI4UbDNv07C"
      },
      "source": [
        "### Run inference on all audio files from this list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbe_3pOqJ97j",
        "outputId": "8010777c-31bc-4257-bc19-8dced4f2f866"
      },
      "source": [
        "!./flashlight/build/bin/asr/fl_asr_tutorial_inference_ctc \\\n",
        "  --am_path=am_transformer_ctc_stride3_letters_300Mparams.bin \\\n",
        "  --tokens_path=tokens.txt \\\n",
        "  --lexicon_path=lexicon.txt \\\n",
        "  --lm_path=lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin \\\n",
        "  --logtostderr=true \\\n",
        "  --sample_rate=16000 \\\n",
        "  --beam_size=50 \\\n",
        "  --beam_size_token=30 \\\n",
        "  --beam_threshold=100 \\\n",
        "  --lm_weight=1.5 \\\n",
        "  --word_score=0 \\\n",
        "  --audio_list=audio.lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1223 21:06:26.336019  9848 InferenceCTC.cpp:65] Gflags after parsing\n",
            "--flagfile=;--fromenv=;--tryfromenv=;--undefok=;--tab_completion_columns=80;--tab_completion_word=;--help=false;--helpfull=false;--helpmatch=;--helpon=;--helppackage=false;--helpshort=false;--helpxml=false;--version=false;--am_path=am_transformer_ctc_stride3_letters_300Mparams.bin;--audio_list=audio.lst;--beam_size=50;--beam_size_token=30;--beam_threshold=100;--lexicon_path=lexicon.txt;--lm_path=lm_common_crawl_small_4gram_prun0-6-15_200kvocab.bin;--lm_weight=1.5;--sample_rate=16000;--tokens_path=tokens.txt;--word_score=0;--alsologtoemail=;--alsologtostderr=false;--colorlogtostderr=false;--drop_log_memory=true;--log_backtrace_at=;--log_dir=;--log_link=;--log_prefix=true;--logbuflevel=0;--logbufsecs=30;--logemaillevel=999;--logfile_mode=436;--logmailer=/bin/mail;--logtostderr=true;--max_log_size=1800;--minloglevel=0;--stderrthreshold=2;--stop_logging_if_full_disk=false;--symbolize_stacktrace=true;--v=0;--vmodule=;\n",
            "I1223 21:06:26.336138  9848 InferenceCTC.cpp:88] [Inference tutorial for CTC] Reading acoustic model from am_transformer_ctc_stride3_letters_300Mparams.bin\n",
            "I1223 21:06:27.375306  9848 InferenceCTC.cpp:137] [Inference tutorial for CTC] Network is loaded.\n",
            "I1223 21:06:27.627107  9848 InferenceCTC.cpp:149] [Inference tutorial for CTC] Number of classes/tokens in the network: 29\n",
            "I1223 21:06:27.627138  9848 InferenceCTC.cpp:152] [Inference tutorial for CTC] Number of words in the lexicon: 200001\n",
            "I1223 21:06:27.814982  9848 InferenceCTC.cpp:163] [Inference tutorial for CTC] Language model is constructed.\n",
            "I1223 21:06:28.711031  9848 InferenceCTC.cpp:174] [Inference tutorial for CTC] Trie is planted.\n",
            "I1223 21:06:28.711067  9848 InferenceCTC.cpp:193] [Inference tutorial for CTC] Beam search decoder is created\n",
            "I1223 21:06:33.423995  9848 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for audio/116-288045-0000.flac\n",
            "as i approached the city i heard bells ringing and a little later i found the streets astir with throngs of well dressed people in family groups winding their way hither and thither\n",
            "I1223 21:06:33.768693  9848 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for audio/116-288045-0001.flac\n",
            "looking about me i saw a gentleman in a neat black dress smiling and his hand extended to me with great cordiality\n",
            "I1223 21:06:33.924844  9848 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for audio/116-288045-0002.flac\n",
            "he must have realized i was a stranger and wished to tender his hospitality to me i accepted it gratefully i clasped his hand he pressed mine\n",
            "I1223 21:06:33.990335  9848 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for audio/116-288045-0003.flac\n",
            "we gazed for a moment slightly into each other's eyes\n",
            "I1223 21:06:34.054947  9848 InferenceCTC.cpp:284] [Inference tutorial for CTC]: predicted output for audio/116-288045-0004.flac\n",
            "of course you are going there too i said to my friendly guide\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BCed5Whw5YQ"
      },
      "source": [
        "## Congrats, you reached the end!\n",
        "![title](https://media1.giphy.com/media/3otPoS81loriI9sO8o/giphy.gif)\n",
        "## Happy Holidays!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-pcTLMH5bUH"
      },
      "source": [
        "## Bonus Alignment: coming soon"
      ]
    }
  ]
}
